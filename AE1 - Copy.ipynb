{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "***AE1***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee154473486c1ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load and pre-processing text**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f19d835b1942a93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load and preprocess the text data, converting it to i) lowercase, ii) removing special\n",
    "characters, iii) digits, and iv) redundant whitespace, v) list of words and vi) excluding\n",
    "meaningless words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ec0a8568b61973"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:49:51.844468300Z",
     "start_time": "2024-03-03T23:49:51.836002300Z"
    }
   },
   "id": "ddce4740641ad48f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#load and read the dataset\n",
    "music_df = pd.read_csv(\"spotify_millsongdata.csv\")\n",
    "\n",
    "#dataset\n",
    "music_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.837002600Z"
    }
   },
   "id": "c7fbdbab6828d1ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Lowercase artist and song name\n",
    "artist_lower = music_df['artist'].str.lower()\n",
    "song_lower = music_df['song'].str.lower()\n",
    "text_lower = music_df['text'].str.lower()\n",
    "\n",
    "#Replace artist and song name in DataFrame with lowercase\n",
    "#music_df = music_df.str.lower()\n",
    "music_df['artist'] = artist_lower\n",
    "music_df['song'] = song_lower\n",
    "music_df['text'] = text_lower\n",
    "music_df\n",
    "#music_lower_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.838002200Z"
    }
   },
   "id": "8e006d0e7b4311fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Ask user for which artists they want to analyze\n",
    "artist1 = input(\"Enter artist 1:\")\n",
    "artist2 = input(\"Enter artist 2:\")\n",
    "\n",
    "artist_list = [artist1.lower(), artist2.lower()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:51:56.029987700Z",
     "start_time": "2024-03-03T23:51:50.756308700Z"
    }
   },
   "id": "760820121d3448cd",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             artist                   song  \\\n0              abba  ahe's my kind of girl   \n1              abba       andante, andante   \n2              abba         as good as new   \n3              abba                   bang   \n4              abba       bang-a-boomerang   \n...             ...                    ...   \n52781  taylor swift             tim mcgraw   \n52782  taylor swift  today was a fairytale   \n52783  taylor swift        white christmas   \n52784  taylor swift            white horse   \n52785  taylor swift         wildest dreams   \n\n                                                    link  \\\n0             /a/abba/ahes+my+kind+of+girl_20598417.html   \n1                  /a/abba/andante+andante_20002708.html   \n2                   /a/abba/as+good+as+new_20003033.html   \n3                             /a/abba/bang_20598415.html   \n4                 /a/abba/bang+a+boomerang_20002668.html   \n...                                                  ...   \n52781           /t/taylor+swift/tim+mcgraw_20359673.html   \n52782  /t/taylor+swift/today+was+a+fairytale_20761546...   \n52783      /t/taylor+swift/white+christmas_20658358.html   \n52784          /t/taylor+swift/white+horse_20761227.html   \n52785       /t/taylor+swift/wildest+dreams_21089668.html   \n\n                                                    text  \n0      look at her face, it's a wonderful face  \\r\\na...  \n1      take it easy with me, please  \\r\\ntouch me gen...  \n2      i'll never know why i had to go  \\r\\nwhy i had...  \n3      making somebody happy is a question of give an...  \n4      making somebody happy is a question of give an...  \n...                                                  ...  \n52781  he said the way my blue eyes shined  \\r\\nput t...  \n52782  today was a fairytale  \\r\\nyou were the prince...  \n52783  i'm dreaming of a white christmas  \\r\\njust li...  \n52784  say you're sorry  \\r\\nthat face of an angel  \\...  \n52785  he said, \"let's get out of this town,  \\r\\ndri...  \n\n[194 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>song</th>\n      <th>link</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abba</td>\n      <td>ahe's my kind of girl</td>\n      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n      <td>look at her face, it's a wonderful face  \\r\\na...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abba</td>\n      <td>andante, andante</td>\n      <td>/a/abba/andante+andante_20002708.html</td>\n      <td>take it easy with me, please  \\r\\ntouch me gen...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abba</td>\n      <td>as good as new</td>\n      <td>/a/abba/as+good+as+new_20003033.html</td>\n      <td>i'll never know why i had to go  \\r\\nwhy i had...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abba</td>\n      <td>bang</td>\n      <td>/a/abba/bang_20598415.html</td>\n      <td>making somebody happy is a question of give an...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abba</td>\n      <td>bang-a-boomerang</td>\n      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n      <td>making somebody happy is a question of give an...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>52781</th>\n      <td>taylor swift</td>\n      <td>tim mcgraw</td>\n      <td>/t/taylor+swift/tim+mcgraw_20359673.html</td>\n      <td>he said the way my blue eyes shined  \\r\\nput t...</td>\n    </tr>\n    <tr>\n      <th>52782</th>\n      <td>taylor swift</td>\n      <td>today was a fairytale</td>\n      <td>/t/taylor+swift/today+was+a+fairytale_20761546...</td>\n      <td>today was a fairytale  \\r\\nyou were the prince...</td>\n    </tr>\n    <tr>\n      <th>52783</th>\n      <td>taylor swift</td>\n      <td>white christmas</td>\n      <td>/t/taylor+swift/white+christmas_20658358.html</td>\n      <td>i'm dreaming of a white christmas  \\r\\njust li...</td>\n    </tr>\n    <tr>\n      <th>52784</th>\n      <td>taylor swift</td>\n      <td>white horse</td>\n      <td>/t/taylor+swift/white+horse_20761227.html</td>\n      <td>say you're sorry  \\r\\nthat face of an angel  \\...</td>\n    </tr>\n    <tr>\n      <th>52785</th>\n      <td>taylor swift</td>\n      <td>wildest dreams</td>\n      <td>/t/taylor+swift/wildest+dreams_21089668.html</td>\n      <td>he said, \"let's get out of this town,  \\r\\ndri...</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new DataFrame with only the inputted artist\n",
    "cleaned_df = music_df.copy()\n",
    "cleaned_df = cleaned_df[cleaned_df['artist'].isin(artist_list)]\n",
    "cleaned_df.fillna('', inplace=True)\n",
    "\n",
    "cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:51:58.756880200Z",
     "start_time": "2024-03-03T23:51:58.698033500Z"
    }
   },
   "id": "a796524ea96e60e1",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Unnecessary text\n",
    "MEANINGLESS = [\"i\", \"a\", \"an\", \"and\", \"the\", \"on\", \"of\", \"in\", \"with\", \"you\",\n",
    "               \"me\", \"to\", \"at\", \"for\", \"[\", \"]\", \"(\", \")\", \"?\", \"!\", \"-\", \" \"]\n",
    "\n",
    "def clean_text(song):\n",
    "    song = re.sub(r'[^a-zA-Z\\s]', '', song)\n",
    "    song = ' '.join([word for word in song.split() if word not in MEANINGLESS])\n",
    "    return song\n",
    "\n",
    "\n",
    "cleaned_df['text'] = cleaned_df['text'].apply(clean_text)\n",
    "cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:49:51.851468900Z",
     "start_time": "2024-03-03T23:49:51.845469300Z"
    }
   },
   "id": "7ea21a5b87e82541",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Analyzing text**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abcbc0f3128170d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyse the processed song lyrics of each specified artist by i) counting the\n",
    "frequency of words, ii) determining the vocabulary richness, iii) scoring the sentiment\n",
    "of song lyrics, and iv) identifying any common words between artists."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c91d4c4f86dc134"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Grouping songs by artist\n",
    "cleaned_group_df = cleaned_df.copy().groupby('artist').sum()\n",
    "cleaned_group_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.846467200Z"
    }
   },
   "id": "c02c11e244382e61",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#function used to count the frequency of words\n",
    "def calculate_frequency(song):\n",
    "    word_frequency = {} #Empty dictionary\n",
    "    words = song.split()\n",
    "    for word in words:\n",
    "        if word_frequency.get(word) is None: #Check if word is in dictionary\n",
    "            word_frequency[word] = 1 #if not add it and set its count to 1\n",
    "        else:\n",
    "            word_frequency[word] = word_frequency[word] + 1 #if in dictionary already add a count\n",
    "    return word_frequency\n",
    "\n",
    "#counting frequency of words for songs\n",
    "song1_frequency = calculate_frequency(cleaned_df['text'][0])\n",
    "song2_frequency = calculate_frequency(cleaned_df['text'][1])\n",
    "\n",
    "#word frequency of words for artists\n",
    "artist1_frequency = calculate_frequency(cleaned_group_df['text'][0])\n",
    "artist2_frequency = calculate_frequency(cleaned_group_df['text'][1])\n",
    "\n",
    "print(song1_frequency)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.847467Z"
    }
   },
   "id": "58a863a2e81ba49c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Determining the vocabulary richness\n",
    "def vocab_richness(song):\n",
    "    return len(calculate_frequency(song))/len(song) #Number of unique words / number of total words\n",
    "\n",
    "#Vocab richness of a song\n",
    "print(vocab_richness(cleaned_df['text'][0]))\n",
    "\n",
    "#Vocab richness of an artist\n",
    "print(vocab_richness(cleaned_group_df['text'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.850480300Z"
    }
   },
   "id": "b0009547a4e5fd8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Updating the cleaned non-grouped dataset with the vocab richness scores or each song\n",
    "y = []\n",
    "\n",
    "for song in cleaned_df['text']:\n",
    "    y.append(vocab_richness(song))\n",
    "cleaned_df['richness'] = y\n",
    "cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:49:51.965280200Z",
     "start_time": "2024-03-03T23:49:51.851468900Z"
    }
   },
   "id": "50e52edecd551287",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Get the artist's names\n",
    "artist1 = cleaned_group_df.index[0]\n",
    "artist2 = cleaned_group_df.index[1]\n",
    "\n",
    "#Seperate the songs by artist into new dataframes\n",
    "df_artist1 = cleaned_df[cleaned_df['artist'] == artist1]\n",
    "df_artist2 = cleaned_df[cleaned_df['artist'] == artist2]\n",
    "\n",
    "#Making barplots of the vocabulary richness of each artist\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "axs[0].set_title(f\"{cleaned_group_df.index[0]} vocab richness\")\n",
    "axs[1].set_title(f\"{cleaned_group_df.index[1]} vocab richness\")\n",
    "\n",
    "sns.barplot(x='song', y='richness', data=df_artist1, ax=axs[0])\n",
    "sns.barplot(x='song', y='richness', data=df_artist2, ax=axs[1])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.853466700Z"
    }
   },
   "id": "f3d08e879a897813",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "# Boxplot for artist1\n",
    "axs[0].set_title(f\"{artist1} vocab richness\")\n",
    "sns.boxplot(x='richness', data=df_artist1, ax=axs[0], color='blue')\n",
    "\n",
    "# Boxplot for artist2\n",
    "axs[1].set_title(f\"{artist2} vocab richness\")\n",
    "sns.boxplot(x='richness', data=df_artist2, ax=axs[1], color='red')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.854467200Z"
    }
   },
   "id": "dc13e5d0922f16ed",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at ABBA and Taylor Swift, there is a positive vocabulary richness for both artists. However, for both it is a very small vocabulary richness with both not even going past .2."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe50152fad64cb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.855468700Z"
    }
   },
   "id": "322362683ec8ba30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Sentiment analysis scsorer\n",
    "def sentiment_analysis(song):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    sentiment_scores = sia.polarity_scores(song)\n",
    "\n",
    "    s_score = sentiment_scores['compound']\n",
    "\n",
    "    if s_score >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif s_score <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "        \n",
    "    return s_score, sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.857467500Z"
    }
   },
   "id": "2860aeddbf09f612",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(sentiment_analysis(cleaned_df['text'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.858469200Z"
    }
   },
   "id": "39febfada0a6d40c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Updating the cleaned non-grouped dataset with the sentiment scores or each song\n",
    "y = []\n",
    "\n",
    "for song in cleaned_df['text']:\n",
    "    y.append(sentiment_analysis(song))\n",
    "cleaned_df['sentiment'] = y\n",
    "cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.861885Z"
    }
   },
   "id": "812684927a0e5813",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Artist names\n",
    "artist1 = cleaned_group_df.index[0]\n",
    "artist2 = cleaned_group_df.index[1]\n",
    "\n",
    "#Seperete songs by artist and into new data frames\n",
    "df_artist1 = cleaned_df[cleaned_df['artist'] == artist1].copy()\n",
    "df_artist2 = cleaned_df[cleaned_df['artist'] == artist2].copy()\n",
    "\n",
    "#Get the numerical part of the sentiment scorer\n",
    "df_artist1['sentiment score'] = df_artist1['sentiment'].apply(lambda x: x[0])\n",
    "df_artist2['sentiment score'] = df_artist2['sentiment'].apply(lambda x: x[0])\n",
    "\n",
    "#Createt the barplots\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "axs[0].set_title(f\"{cleaned_group_df.index[0]} sentiment score\")\n",
    "axs[1].set_title(f\"{cleaned_group_df.index[1]} sentiment score\")\n",
    "\n",
    "sns.barplot(x='song', y='sentiment score', data=df_artist1, ax=axs[0])\n",
    "sns.barplot(x='song', y='sentiment score', data=df_artist2, ax=axs[1])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.862882800Z"
    }
   },
   "id": "df8566c3cd0511d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "# Boxplot for artist1\n",
    "axs[0].set_title(f\"{artist1} sentiment score\")\n",
    "sns.boxplot(x='sentiment score', data=df_artist1, ax=axs[0], color='blue')\n",
    "\n",
    "# Boxplot for artist2\n",
    "axs[1].set_title(f\"{artist2} sentiment score\")\n",
    "sns.boxplot(x='sentiment score', data=df_artist2, ax=axs[1], color='red')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.864884100Z"
    }
   },
   "id": "367541f48a5c9efd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at ABBA and Taylor Swift again we can see mostly positive sentiment scores. Both score very high with both having medians and maximums at 1 with outliers in the negatives close to -1. This shows that both artists typically write songs near the extreme levels of sentiment. The songs are generally very positive or very negative."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f846aa0f1a54a44"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Empty dictionaries for common words\n",
    "common_words = []\n",
    "artist1 = calculate_frequency(cleaned_group_df['text'][0])\n",
    "artist2 = calculate_frequency(cleaned_group_df['text'][1])\n",
    "for word in artist1:\n",
    "    if artist2.get(word) is not None:\n",
    "        common_words.append(word)\n",
    "\n",
    "print(common_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.865882500Z"
    }
   },
   "id": "6d5121417c0b93b5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Visualising text**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d07ec77f8c0f71db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualise the analysed data by i) generating word clouds for each artist, ii) plotting\n",
    "sentiment scores in a scatter plot, and iii) creating a heat map to show word overlap\n",
    "between artists."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4ba2ed4885bd9e2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Word Cloud based on words alone\n",
    "def word_cloud():\n",
    "    cloud = WordCloud()\n",
    "    cloud1 = WordCloud()\n",
    "    artist1_cloud = cloud.generate(cleaned_group_df['text'][0])\n",
    "    artist2_cloud = cloud1.generate(cleaned_group_df['text'][1])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[0].set_title(cleaned_group_df.index[0])\n",
    "    axs[1].set_title(cleaned_group_df.index[1])\n",
    "    axs[0].imshow(artist1_cloud)\n",
    "    axs[1].imshow(artist2_cloud)\n",
    "    plt.show()\n",
    "\n",
    "#Word Cloud based on frequency of words\n",
    "def word_cloud_frequency():\n",
    "    artist1_words = calculate_frequency(cleaned_group_df['text'][0])\n",
    "    artist2_words = calculate_frequency(cleaned_group_df['text'][1])\n",
    "    #print(artist1_words)\n",
    "    #print(artist2_words)\n",
    "    \n",
    "    cloud = WordCloud()\n",
    "    cloud1 = WordCloud()\n",
    "    \n",
    "    artist1_cloud = cloud.generate_from_frequencies(artist1_words)\n",
    "    artist2_cloud = cloud1.generate_from_frequencies(artist2_words)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[0].set_title(f\"{cleaned_group_df.index[0]} (frequency)\")\n",
    "    axs[1].set_title(f\"{cleaned_group_df.index[1]} (frequency)\")\n",
    "    axs[0].imshow(artist1_cloud)\n",
    "    axs[1].imshow(artist2_cloud)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.867883600Z"
    }
   },
   "id": "fc2fd7de69a6fb58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "word_cloud()\n",
    "word_cloud_frequency()\n",
    "# Save the cloud image to a file\n",
    "#cloud.to_file('WC.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.869883600Z"
    }
   },
   "id": "1057c0cf5fcfb890",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Get the names of the two artists\n",
    "artist1 = cleaned_group_df.index[0]\n",
    "artist2 = cleaned_group_df.index[1]\n",
    "\n",
    "#Create empty lists for artist sentiment and richness\n",
    "artist1_sentiment = []\n",
    "artist2_sentiment = []\n",
    "artist1_richness = []\n",
    "artist2_richness = []\n",
    "\n",
    "#Get the sentiment and vocab richness of each song for each artist and add it to the respective list\n",
    "for index, row in cleaned_df.iterrows():\n",
    "    score, _ = sentiment_analysis(row['text'])\n",
    "    richness = vocab_richness(row['text'])\n",
    "    if row['artist'] == artist1:\n",
    "        artist1_sentiment.append(score)\n",
    "        artist1_richness.append(richness)\n",
    "    else:\n",
    "        artist2_sentiment.append(score)\n",
    "        artist2_richness.append(richness)\n",
    "\n",
    "#Create a data frame for each artist of richness x sentiment\n",
    "plot1 = pd.DataFrame({'artist1_richness': artist1_richness, 'artist1_sentiment': artist1_sentiment})\n",
    "plot2 = pd.DataFrame({'artist2_richness': artist2_richness, 'artist2_sentiment': artist2_sentiment})\n",
    "\n",
    "#Plot the data\n",
    "#Artist 1\n",
    "sns.relplot(data = plot1, x = artist1_richness, y = artist1_sentiment, label=artist1, color = 'blue')\n",
    "plt.xlabel(\"Vocabulary Richness\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.title(f\"{artist1} Richness x Sentiment\")\n",
    "\n",
    "#Artist 2\n",
    "sns.relplot(data = plot2, x = artist2_richness, y = artist2_sentiment, label=artist2, color = 'red')\n",
    "plt.xlabel(\"Vocabulary Richness\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.title(f\"{artist2} Richness x Sentiment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.871882300Z"
    }
   },
   "id": "966c00c797a4d35e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66f10e4271a80535"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 10))\n",
    "fig.subplots_adjust(wspace = .5)\n",
    "\n",
    "#Linear Regression Model\n",
    "model = LinearRegression()\n",
    "#Train the model\n",
    "x = df_artist1['richness'].values.reshape(-1, 1)\n",
    "y = df_artist1['sentiment'].apply(lambda x: x[0])\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict y-value for 1,000 data points in range from the minimum to the maximum of artist 1's richness\n",
    "u = np.linspace(df_artist1['richness'].min(), df_artist1['richness'].max(), 1000)\n",
    "v = model.predict(u[:, np.newaxis])\n",
    "\n",
    "#Plot the raw data and the predicted line\n",
    "axs[0].set_xlabel('Richness')\n",
    "axs[0].set_ylabel('Sentiment')\n",
    "axs[0].set_title(f\"{cleaned_group_df.index[0]} Predicted Vocab Richness vs Sentiment\")\n",
    "axs[0].scatter(x = df_artist1['richness'], y = y, color = 'blue', label = 'Actual')\n",
    "axs[0].plot(u, v, color = 'purple', label = 'Predicted')\n",
    "axs[0].legend(bbox_to_anchor=(1.25, 1.0))\n",
    "print(f'y(x) = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')\n",
    "\n",
    "#Train the model\n",
    "x1 = df_artist2['richness'].values.reshape(-1, 1)\n",
    "y1 = df_artist2['sentiment'].apply(lambda x: x[0])\n",
    "model.fit(x1, y1)\n",
    "\n",
    "# Predict y-value for 1,000 data points in range from the minimum to the maximum of artist 2's richness\n",
    "u = np.linspace(df_artist1['richness'].min(), df_artist1['richness'].max(), 1000)\n",
    "v = model.predict(u[:, np.newaxis])\n",
    "\n",
    "#Plot the raw data and the predicted line\n",
    "axs[1].set_xlabel('Richness')\n",
    "axs[1].set_ylabel('Sentiment')\n",
    "axs[1].scatter(x = df_artist2['richness'], y = y1, color = 'red', label = 'Actual')\n",
    "axs[1].plot(u, v, color = 'orange', label = 'Predicted')\n",
    "axs[1].set_title(f\"{cleaned_group_df.index[1]} Predicted Vocab Richness vs Sentiment\")\n",
    "plt.legend(bbox_to_anchor=(1, 1.0))\n",
    "print(f'y(x) = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.872883500Z"
    }
   },
   "id": "fe1867945a398eec",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at ABBA and Taylor Swift, we can see a negative correlation in terms of Vocabulary Richness vs Sentiment for both artists. Using the predicted models of each plot, we can see ABBA has a negative slope of 2.729 and Taylor Swift has a negative slope of 0.907. This means that as their vocabulary richness increases, their sentiment score decreases. In other words, as their songs get more word diversity, the negativity of their song increases."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "216d89c5ff691dbf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Heatmap of only shared words\n",
    "#Create an empty data frame\n",
    "count_df = pd.DataFrame()\n",
    "\n",
    "#function used to count how many of the common words appear for each artist\n",
    "def count_common_words(lyrics):\n",
    "    lyric_words = lyrics.split()\n",
    "    word_counts = Counter(lyric_words)\n",
    "    common_word_counts = {wrd: word_counts[wrd] for wrd in common_words}\n",
    "    return common_word_counts\n",
    "\n",
    "#Update the data frame \n",
    "count_df[cleaned_group_df.index[0]] = count_common_words(cleaned_group_df['text'][0]).values()\n",
    "count_df[cleaned_group_df.index[1]] = count_common_words(cleaned_group_df['text'][1]).values()\n",
    "\n",
    "count_df.index = common_words\n",
    "\n",
    "sns.heatmap(count_df, annot=True, fmt='g')\n",
    "plt.title(f'Heatmap of {cleaned_group_df.index[0]} and {cleaned_group_df.index[1]} common words')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.873882400Z"
    }
   },
   "id": "c28220876edc2eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Heatmap of all words\n",
    "count_df = pd.DataFrame()\n",
    "\n",
    "def count_word_occurrences(lyrics):\n",
    "    lyric_words = lyrics.split()\n",
    "    word_counts = Counter(lyric_words)\n",
    "    return word_counts\n",
    "\n",
    "#Update the data frame \n",
    "count_df[cleaned_group_df.index[0]] = pd.Series(count_word_occurrences(cleaned_group_df['text'][0]).values())\n",
    "count_df[cleaned_group_df.index[1]] = pd.Series(count_word_occurrences(cleaned_group_df['text'][1]).values())\n",
    "\n",
    "#Create a set of unique words from the data frame\n",
    "all_unique_words = set(count_df[cleaned_group_df.index[0]].index).union(set(count_df[cleaned_group_df.index[1]].index))\n",
    "count_df = count_df.reindex(all_unique_words, fill_value=0)\n",
    "\n",
    "heatmap_df = pd.DataFrame(columns=count_df.index, index=count_df.index)\n",
    "\n",
    "#Count how many times common words appear\n",
    "for artist1 in heatmap_df.index:\n",
    "    for artist2 in heatmap_df.columns:\n",
    "        count_common = len(set(count_df.loc[artist1].index) & set(count_df.loc[artist2].index))\n",
    "        heatmap_df.at[artist1, artist2] = count_common\n",
    "\n",
    "sns.heatmap(count_df, annot=True, fmt='g')\n",
    "plt.title(f'Heatmap of {cleaned_group_df.index[0]} and {cleaned_group_df.index[1]} common words')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.874882100Z"
    }
   },
   "id": "5a058fc9ed719b80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Generating text**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15559ebe2ad9ee0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a text generator that allows the user to specify the number of n-grams\n",
    "and generate two new songs based on the lyrics of the specified artists."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc5c10521c169b00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#N-gram generator\n",
    "import random\n",
    "def ngram(lyrics, n):\n",
    "    words = lyrics.split()\n",
    "    l_ngrams = zip(*[words[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in l_ngrams]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.877883Z"
    }
   },
   "id": "12b693bc8a01bcb7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Get the number of n-grams desired from the user\n",
    "gram = int(input(\"Enter the n-gram number: \"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.879885100Z"
    }
   },
   "id": "607b003fc818ca54"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Create the list of n-grams\n",
    "ngrams = ngram(cleaned_group_df['text'][0], gram)\n",
    "ngrams1 = ngram(cleaned_group_df['text'][1], gram)\n",
    "\n",
    "print(ngrams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.881882500Z"
    }
   },
   "id": "8969aaaa24f59f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Song 1\n",
    "for i in range(40):\n",
    "    print(random.choice(ngrams))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.882883700Z"
    }
   },
   "id": "64b621b3e559d7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Song 2\n",
    "for i in range(40):\n",
    "    print(random.choice(ngrams1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T23:49:51.884882400Z"
    }
   },
   "id": "1a299046ac502bbc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reflection**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea20c6c117753307"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a reflection on your experience working on this project. Discuss the challenges\n",
    "you encountered during the development of the application, the solutions you\n",
    "implemented, and the lessons you learned from the project. Reflect on the\n",
    "effectiveness of the techniques used and propose potential improvements for future\n",
    "iterations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "983e8251a795217b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A big challenge for me working on this project was creating the heatmap. Although I had worked with heatmaps in the past, I wasn't sure how to implement the dataset into the code. The main problem was that I couldn't figure out how to create a square 2D array of the common words between the two chosen artists. My first successful attempt at generating a heatmap gave me the x-axis as the artists and the y-axis as the common words. My solution consisted of creating a new data frame and updating it with the number of common words each artist had via a function I made. However, because there were so many common words, the heatmap had to condense most of them which made it hard to tell which words were actually used more often. This is something that I would like to improve on in future iterations by making the heatmap more clear and readable to users. Another problem I had was with the linear regression model I created. Even though I had also worked with linear regression models before, I was still confused about what each function used to make it worked. I tried using sns.regplot at first because it seemed easier and more efficient. However after some testing and failures I started using LinearRegression from sklearn and tried to understand every part that makes up a linear regression model. I eventually figured it out and was able to make models of the vocabulary richness vs sentiment. If I could improve it I would try to use sns.regplot since it seems more effective and simpler than sklearn. A lot of the other parts of the project were fairly simple since we had practiced them in the labs. Although there were some unfamiliar sections I hadn't worked a lot with yet like the sentiment analysis and word cloud, I reviewed the previous labs and researched online for solutions and eventually was able to figure it out. For the most part, the most time-consuming part of this project was combining all I had learned in class and adjusting the code based on my needs and the dataset. Another improvement I would like to make is making the code faster. Because the dataset is so large, some of the code blocks take longer than I'd like so making them run faster would be a good improvement. Overall I think I was able to implement what I learned in class fairly well and the techniques and skills I used such as pandas and seaborn helped me a lot in simplifying my code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbdb94b84c50e76b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
